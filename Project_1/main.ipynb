{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from power_outage_data import load_yearly_data, load_fips_shapes, lat_lon_to_fips\n",
    "from storm_data import (\n",
    "    load_clusters,\n",
    "    load_tracks,\n",
    "    date_str_to_storm_time,\n",
    "    storm_time_to_datetime,\n",
    "    get_intensity\n",
    ")\n",
    "\n",
    "yearly_power_data = load_yearly_data()\n",
    "fips_shapes = load_fips_shapes()\n",
    "clusters = load_clusters()\n",
    "# Load tracks and prefilter for year.\n",
    "tks = load_tracks()\n",
    "tks = tks.where(tks.season>=2014, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'storm': 21,\n",
       " 'sid': '2019299N25265',\n",
       " 'name': 'OLGA',\n",
       " 'fullmoment_label': 0,\n",
       " 'spatmoment_label': 0,\n",
       " 'first_landfall_time': '2019-10-26 06:00:00',\n",
       " 'final_landfall_time': '2019-10-27 15:00:00',\n",
       " 'year': 2019,\n",
       " 'intensity': np.float32(45.0),\n",
       " 'times': [datetime.datetime(2019, 10, 26, 6, 0),\n",
       "  datetime.datetime(2019, 10, 26, 9, 0),\n",
       "  datetime.datetime(2019, 10, 26, 12, 0),\n",
       "  datetime.datetime(2019, 10, 26, 15, 0),\n",
       "  datetime.datetime(2019, 10, 26, 18, 0),\n",
       "  datetime.datetime(2019, 10, 26, 21, 0),\n",
       "  datetime.datetime(2019, 10, 27, 0, 0),\n",
       "  datetime.datetime(2019, 10, 27, 3, 0),\n",
       "  datetime.datetime(2019, 10, 27, 6, 0),\n",
       "  datetime.datetime(2019, 10, 27, 9, 0),\n",
       "  datetime.datetime(2019, 10, 27, 12, 0),\n",
       "  datetime.datetime(2019, 10, 27, 15, 0)],\n",
       " 'lon': array([-91.200005, -90.554405, -90.      , -89.65197 , -89.3     ,\n",
       "        -88.67649 , -88.      , -87.565056, -87.      , -86.10014 ,\n",
       "        -84.7     , -82.69062 ], dtype=float32),\n",
       " 'lat': array([28.8     , 30.048195, 31.7     , 33.874447, 36.2     , 38.3074  ,\n",
       "        40.1     , 41.43971 , 42.5     , 43.56252 , 44.5     , 45.30344 ],\n",
       "       dtype=float32),\n",
       " 'fips_code': [None,\n",
       "  '22095',\n",
       "  '28077',\n",
       "  '28161',\n",
       "  '47045',\n",
       "  '17191',\n",
       "  '17019',\n",
       "  '17197',\n",
       "  None,\n",
       "  '26127',\n",
       "  '26143',\n",
       "  None],\n",
       " 'county': [None,\n",
       "  'St. John the Baptist',\n",
       "  'Lawrence',\n",
       "  'Yalobusha',\n",
       "  'Dyer',\n",
       "  'Wayne',\n",
       "  'Champaign',\n",
       "  'Will',\n",
       "  None,\n",
       "  'Oceana',\n",
       "  'Roscommon',\n",
       "  None]}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iterate over each cluster\n",
    "\n",
    "def lookup_storms_in_cluster(cluster):\n",
    "    storm_dicts = []\n",
    "    for _, row in cluster.iterrows():\n",
    "        d = row.to_dict()\n",
    "        start = date_str_to_storm_time(d['first_landfall_time']) - 0.01\n",
    "        end = date_str_to_storm_time(d['final_landfall_time']) + 0.01\n",
    "        sid = bytes(d['sid'], 'utf-8')\n",
    "\n",
    "        storms = tks.where(\n",
    "            (tks['time'] >= start) & (tks['time'] <= end) & (tks['sid'] == sid),\n",
    "            drop=True\n",
    "        )\n",
    "        storm = storms.sel(storm=0)\n",
    "        lon = storm.lon.values\n",
    "        lat = storm.lat.values\n",
    "        fips_codes = []\n",
    "        county = []\n",
    "        state = []\n",
    "        for lat, lon in zip(lat, lon):\n",
    "            fips = lat_lon_to_fips(lat, lon, fips_shapes)\n",
    "            if fips:\n",
    "                fips_codes.append(fips['id'])\n",
    "                county.append(fips['properties']['NAME'])\n",
    "                state.append(fips['properties']['STATE'])\n",
    "            else:\n",
    "                fips_codes.append(None)\n",
    "                county.append(None)\n",
    "                state.append(None)\n",
    "\n",
    "        storm_dict = {\n",
    "            **d,\n",
    "            'year': int(storm.season.values[0]),\n",
    "            'intensity': get_intensity(storm),\n",
    "            'times': [storm_time_to_datetime(time) for time in storm.time.values],\n",
    "            'lon': storm.lon.values,\n",
    "            'lat': storm.lat.values,\n",
    "            'fips_code': fips_codes,\n",
    "            'county': county\n",
    "        }\n",
    "        storm_dicts.append(storm_dict)\n",
    "\n",
    "    return storm_dicts\n",
    "\n",
    "\n",
    "cluster_0 = list(clusters)[0][1]\n",
    "\n",
    "cluster_0_storms = lookup_storms_in_cluster(cluster_0)\n",
    "cluster_0_storms[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize a cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fips_code</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>customers_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>2018-05-28</td>\n",
       "      <td>18</td>\n",
       "      <td>29.799997</td>\n",
       "      <td>-85.900002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12131</td>\n",
       "      <td>2018-05-28</td>\n",
       "      <td>21</td>\n",
       "      <td>30.299997</td>\n",
       "      <td>-86.000000</td>\n",
       "      <td>Walton</td>\n",
       "      <td>Florida</td>\n",
       "      <td>563.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12131</td>\n",
       "      <td>2018-05-29</td>\n",
       "      <td>0</td>\n",
       "      <td>30.900000</td>\n",
       "      <td>-86.099998</td>\n",
       "      <td>Walton</td>\n",
       "      <td>Florida</td>\n",
       "      <td>535.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01039</td>\n",
       "      <td>2018-05-29</td>\n",
       "      <td>3</td>\n",
       "      <td>31.413733</td>\n",
       "      <td>-86.326035</td>\n",
       "      <td>Covington</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>235.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01013</td>\n",
       "      <td>2018-05-29</td>\n",
       "      <td>6</td>\n",
       "      <td>31.900000</td>\n",
       "      <td>-86.599998</td>\n",
       "      <td>Butler</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>01001</td>\n",
       "      <td>2018-05-29</td>\n",
       "      <td>9</td>\n",
       "      <td>32.434963</td>\n",
       "      <td>-86.815224</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2556.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>01007</td>\n",
       "      <td>2018-05-29</td>\n",
       "      <td>12</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>-87.000000</td>\n",
       "      <td>Bibb</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>493.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>01073</td>\n",
       "      <td>2018-05-29</td>\n",
       "      <td>15</td>\n",
       "      <td>33.592453</td>\n",
       "      <td>-87.157814</td>\n",
       "      <td>Jefferson</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>11355.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>01133</td>\n",
       "      <td>2018-05-29</td>\n",
       "      <td>18</td>\n",
       "      <td>34.200001</td>\n",
       "      <td>-87.300003</td>\n",
       "      <td>Winston</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>581.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>01033</td>\n",
       "      <td>2018-05-29</td>\n",
       "      <td>21</td>\n",
       "      <td>34.792480</td>\n",
       "      <td>-87.450264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>47181</td>\n",
       "      <td>2018-05-30</td>\n",
       "      <td>0</td>\n",
       "      <td>35.400002</td>\n",
       "      <td>-87.599998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>47085</td>\n",
       "      <td>2018-05-30</td>\n",
       "      <td>3</td>\n",
       "      <td>36.027546</td>\n",
       "      <td>-87.786736</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>21221</td>\n",
       "      <td>2018-05-30</td>\n",
       "      <td>6</td>\n",
       "      <td>36.700001</td>\n",
       "      <td>-87.900002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>21233</td>\n",
       "      <td>2018-05-30</td>\n",
       "      <td>9</td>\n",
       "      <td>37.419834</td>\n",
       "      <td>-87.874504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>18051</td>\n",
       "      <td>2018-05-30</td>\n",
       "      <td>12</td>\n",
       "      <td>38.200001</td>\n",
       "      <td>-87.699997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>18153</td>\n",
       "      <td>2018-05-30</td>\n",
       "      <td>15</td>\n",
       "      <td>39.042427</td>\n",
       "      <td>-87.409882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18107</td>\n",
       "      <td>2018-05-30</td>\n",
       "      <td>18</td>\n",
       "      <td>39.900002</td>\n",
       "      <td>-87.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18015</td>\n",
       "      <td>2018-05-30</td>\n",
       "      <td>21</td>\n",
       "      <td>40.677132</td>\n",
       "      <td>-86.549927</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18039</td>\n",
       "      <td>2018-05-31</td>\n",
       "      <td>0</td>\n",
       "      <td>41.500000</td>\n",
       "      <td>-86.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>26015</td>\n",
       "      <td>2018-05-31</td>\n",
       "      <td>3</td>\n",
       "      <td>42.432819</td>\n",
       "      <td>-85.321503</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>26111</td>\n",
       "      <td>2018-05-31</td>\n",
       "      <td>6</td>\n",
       "      <td>43.500000</td>\n",
       "      <td>-84.599998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>26135</td>\n",
       "      <td>2018-05-31</td>\n",
       "      <td>9</td>\n",
       "      <td>44.710236</td>\n",
       "      <td>-83.935112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fips_code         day  hour  ...     county    state customers_out\n",
       "0       None  2018-05-28    18  ...        NaN      NaN           NaN\n",
       "1      12131  2018-05-28    21  ...     Walton  Florida         563.0\n",
       "2      12131  2018-05-29     0  ...     Walton  Florida         535.0\n",
       "3      01039  2018-05-29     3  ...  Covington  Alabama         235.0\n",
       "4      01013  2018-05-29     6  ...     Butler  Alabama        1310.0\n",
       "5      01001  2018-05-29     9  ...    Autauga  Alabama        2556.0\n",
       "6      01007  2018-05-29    12  ...       Bibb  Alabama         493.0\n",
       "7      01073  2018-05-29    15  ...  Jefferson  Alabama       11355.0\n",
       "8      01133  2018-05-29    18  ...    Winston  Alabama         581.0\n",
       "9      01033  2018-05-29    21  ...        NaN      NaN           NaN\n",
       "10     47181  2018-05-30     0  ...        NaN      NaN           NaN\n",
       "11     47085  2018-05-30     3  ...        NaN      NaN           NaN\n",
       "12     21221  2018-05-30     6  ...        NaN      NaN           NaN\n",
       "13     21233  2018-05-30     9  ...        NaN      NaN           NaN\n",
       "14     18051  2018-05-30    12  ...        NaN      NaN           NaN\n",
       "15     18153  2018-05-30    15  ...        NaN      NaN           NaN\n",
       "16     18107  2018-05-30    18  ...        NaN      NaN           NaN\n",
       "17     18015  2018-05-30    21  ...        NaN      NaN           NaN\n",
       "18     18039  2018-05-31     0  ...        NaN      NaN           NaN\n",
       "19     26015  2018-05-31     3  ...        NaN      NaN           NaN\n",
       "20     26111  2018-05-31     6  ...        NaN      NaN           NaN\n",
       "21     26135  2018-05-31     9  ...        NaN      NaN           NaN\n",
       "\n",
       "[22 rows x 8 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "storm = cluster_0_storms[0]\n",
    "power_outage_data = yearly_power_data[storm['year']]\n",
    "\n",
    "storm_df = pd.DataFrame({\n",
    "    'fips_code': storm['fips_code'],\n",
    "    'date': [time.date() for time in storm['times']],\n",
    "    'hour': [time.hour for time in storm['times']],\n",
    "    'lat': storm['lat'],\n",
    "    'lon': storm['lon'],\n",
    "})\n",
    "storm_df\n",
    "merged  = storm_df.merge(power_outage_data.drop(columns='hour'), on=['fips_code', 'date'], how='left')\n",
    "merged\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
